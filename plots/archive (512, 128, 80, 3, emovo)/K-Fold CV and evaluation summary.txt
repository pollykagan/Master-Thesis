# channels=[20, 40, 30, 10]; mlp_units=[400, 100, 13]; pooling_indices=[0, 1]; pooling_size=3; kernel_size=4; dropout=0.1; regularization_coefficient=1e-06; batch_size=16; learning_rate=0.005
# SUMMARY for this architecture: pooling_size=3; kernel_size=4; dropout=0.1; regularization_coefficient=0.000001; batch_size=16; learning_rate=0.005

# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.35; regularization_coefficient=1e-05; batch_size=32; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.2; regularization_coefficient=0; batch_size=80; learning_rate=0.001
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.25; regularization_coefficient=1e-06; batch_size=64; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.15; regularization_coefficient=0; batch_size=16; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.25; regularization_coefficient=1e-06; batch_size=64; learning_rate=0.01
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.3; regularization_coefficient=0; batch_size=32; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.35; regularization_coefficient=1e-05; batch_size=16; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.2; regularization_coefficient=1e-06; batch_size=16; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.3; regularization_coefficient=1e-05; batch_size=80; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.1; regularization_coefficient=1e-06; batch_size=32; learning_rate=0.001
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.35; regularization_coefficient=0; batch_size=32; learning_rate=0.01
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.1; regularization_coefficient=0; batch_size=80; learning_rate=0.001
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.1; regularization_coefficient=0; batch_size=48; learning_rate=0.005
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.1; regularization_coefficient=1e-05; batch_size=16; learning_rate=0.001
# channels=[80, 60, 40, 20]; mlp_units=[800, 80]; pooling_indices=[0, 1, 3]; pooling_size=3; kernel_size=3; dropout=0.15; regularization_coefficient=0; batch_size=80; learning_rate=0.001
# SUMMARY for this architecture: pooling_size=3; kernel_size=3; dropout=0.15; regularization_coefficient=0; batch_size=48; learning_rate=0.001

# EVALUTION for [20, 40, 30, 10]
# Training Loss = 0.0346764512360096. Training Accuracy = 0.9900497794151306
# Validation Loss = 0.13021229207515717. Validation Accuracy = 0.970370352268219
# Test Loss = 0.17642652988433838. Test Accuracy = 0.9481481313705444

# EVALUTION for [80, 60, 40, 20]
# Training Loss = 0.0013573424657806754. Training Accuracy = 1.0
# Validation Loss = 0.10831749439239502. Validation Accuracy = 0.9851852059364319
# Test Loss = 0.14433039724826813. Test Accuracy = 0.9777777791023254